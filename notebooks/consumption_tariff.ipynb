{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import is3_broker_rl\n",
    "from is3_broker_rl.api.dto import Action\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\"retina\")\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(is3_broker_rl.__file__).parent.parent / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Papermill parameter cell\n",
    "# Name of the directory to analyse. Should contain consumption_action.csv and consumption_reward.csv.\n",
    "ANALYSIS_DIR_NAME = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANALYSIS_DIR = DATA_DIR / ANALYSIS_DIR_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_action = pd.read_csv(ANALYSIS_DIR / \"consumption_action.csv\")\n",
    "df_reward = pd.read_csv(ANALYSIS_DIR / \"consumption_reward.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ACTION_VALUE_MAPPING = {a.name: a.value for a in Action}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixes the issue that the experiment scheduler always assigns the same gameId\n",
    "def write_unique_game_id(df):\n",
    "    new_game_start_indices = df[df[\"timeslot\"] < df[\"timeslot\"].shift()].index\n",
    "    df.loc[: new_game_start_indices[0], \"gameId\"] = f\"game0\"\n",
    "    for i in range(len(new_game_start_indices) - 1):\n",
    "        df.loc[new_game_start_indices[i] : new_game_start_indices[i + 1], \"gameId\"] = f\"game{i + 1}\"\n",
    "    df.loc[new_game_start_indices[-1] :, \"gameId\"] = f\"game{len(new_game_start_indices)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_unique_game_id(df_reward)\n",
    "write_unique_game_id(df_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_action_counts(df_action):\n",
    "    fig, ax = plt.subplots(figsize=(16, 9))\n",
    "    sns.countplot(x=\"action\", data=df_action, ax=ax, order=ACTION_VALUE_MAPPING.values())\n",
    "    ax.set_xticklabels(ACTION_VALUE_MAPPING.keys())\n",
    "    ax.set_xlabel(\"Action type\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.set_title(\"Action distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_action_counts(df_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_action_count_over_time(df_action, df_reward):\n",
    "    fig, axs = plt.subplots(figsize=(21, 14), nrows=len(ACTION_VALUE_MAPPING), sharey=True)\n",
    "    action_value_counts = (\n",
    "        df_action[[\"gameId\", \"action\"]]\n",
    "        .groupby([\"gameId\", \"action\"], sort=False)\n",
    "        .size()\n",
    "        .unstack(fill_value=0)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    timeslots_per_game = df_reward.groupby(\"gameId\", sort=False).count()[\"timeslot\"].reset_index(drop=True)\n",
    "    action_per_reward = np.ceil(len(df_reward) / len(df_action))\n",
    "    action_value_fractions = action_value_counts.divide(timeslots_per_game, axis=0) * action_per_reward\n",
    "\n",
    "    for i, action_value in enumerate(ACTION_VALUE_MAPPING.values()):\n",
    "        ax = axs.flat[i]\n",
    "        sns.lineplot(data=action_value_fractions[action_value], ax=ax)\n",
    "        ax.set_title(\n",
    "            f\"Fraction of action={list(ACTION_VALUE_MAPPING.keys())[list(ACTION_VALUE_MAPPING.values()).index(action_value)]} over time for each game\"\n",
    "        )\n",
    "        ax.set_xlabel(\"Game number\")\n",
    "        ax.set_ylabel(\"Action count fraction\")\n",
    "        ax.set_ylim((0, action_value_fractions.max().max()))\n",
    "        ax.set_xticks(action_value_fractions.index)\n",
    "        ax.margins(x=0)\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_action_count_over_time(df_action, df_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timestep_reward(df_reward):\n",
    "    window_size = 168\n",
    "    fig, ax = plt.subplots(figsize=(16, 9))\n",
    "    sns.lineplot(data=df_reward[\"reward\"].rolling(window_size).mean(), ax=ax)\n",
    "    ax.set_xlabel(\"Timeslot\")\n",
    "    ax.set_ylabel(\"Reward\")\n",
    "    ax.set_title(f\"Rolling mean reward with window size {window_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_timestep_reward(df_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_episode_reward(df_reward, df_action):\n",
    "    fig, ax = plt.subplots(figsize=(21, 11))\n",
    "    df_mean_episode_reward = df_reward.groupby(\"episode_id\", sort=False).mean().reset_index()\n",
    "    df_max_episode_reward = df_reward.groupby(\"episode_id\", sort=False).max().reset_index()\n",
    "    df_min_episode_reward = df_reward.groupby(\"episode_id\", sort=False).min().reset_index()\n",
    "    sns.lineplot(\n",
    "        x=df_mean_episode_reward.index, y=\"reward\", data=df_mean_episode_reward, ax=ax, label=\"Mean episode reward\"\n",
    "    )\n",
    "    sns.lineplot(\n",
    "        x=df_max_episode_reward.index, y=\"reward\", data=df_max_episode_reward, ax=ax, label=\"Max episode reward\"\n",
    "    )\n",
    "    sns.lineplot(\n",
    "        x=df_min_episode_reward.index, y=\"reward\", data=df_min_episode_reward, ax=ax, label=\"Min episode reward\"\n",
    "    )\n",
    "    df_episode_game_id = df_reward.groupby(\"episode_id\", sort=False)[\"gameId\"].first().reset_index()\n",
    "    ax.vlines(\n",
    "        df_episode_game_id[df_episode_game_id[\"gameId\"].shift() != df_episode_game_id[\"gameId\"]].index,\n",
    "        0,\n",
    "        1,\n",
    "        transform=ax.get_xaxis_transform(),\n",
    "        colors=\"r\",\n",
    "        alpha=0.3,\n",
    "        label=\"New game\",\n",
    "    )\n",
    "    ax.set_xlabel(\"Episode\")\n",
    "    ax.set_ylabel(\"Aggregated reward\")\n",
    "    ax.legend()\n",
    "    ax.set_title(f\"Episode reward (N_EPISODES: {df_reward['episode_id'].nunique()}, N_TIMESTEPS: {len(df_action)})\")\n",
    "    ax.margins(x=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_episode_reward(df_reward, df_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_episode_reward_reg(df_reward, df_action):\n",
    "    fig, ax = plt.subplots(figsize=(21, 11))\n",
    "    df_mean_episode_reward = df_reward.groupby(\"episode_id\", sort=False).mean().reset_index()\n",
    "    sns.regplot(\n",
    "        x=df_mean_episode_reward.index,\n",
    "        y=\"reward\",\n",
    "        data=df_mean_episode_reward,\n",
    "        scatter=True,\n",
    "        marker=\".\",\n",
    "        ax=ax,\n",
    "        label=\"Mean episode reward\",\n",
    "        line_kws={\"label\": \"OLS fit\"},\n",
    "    )\n",
    "    df_episode_game_id = df_reward.groupby(\"episode_id\", sort=False)[\"gameId\"].first().reset_index()\n",
    "    ax.vlines(\n",
    "        df_episode_game_id[df_episode_game_id[\"gameId\"].shift() != df_episode_game_id[\"gameId\"]].index,\n",
    "        0,\n",
    "        1,\n",
    "        transform=ax.get_xaxis_transform(),\n",
    "        colors=\"r\",\n",
    "        alpha=0.3,\n",
    "        label=\"New game\",\n",
    "    )\n",
    "    ax.set_xlabel(\"Episode\")\n",
    "    ax.set_ylabel(\"Aggregated reward\")\n",
    "    ax.legend()\n",
    "    ax.set_title(\n",
    "        f\"Mean episode reward (N_EPISODES: {df_reward['episode_id'].nunique()}, N_TIMESTEPS: {len(df_action)})\"\n",
    "    )\n",
    "    ax.margins(x=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_episode_reward_reg(df_reward, df_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.014027,
     "end_time": "2022-07-04T13:48:21.702232",
     "exception": false,
     "start_time": "2022-07-04T13:48:21.688205",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_mean_reward_per_action(df_reward):\n",
    "    fig, ax = plt.subplots(figsize=(21, 11))\n",
    "    df_reward = df_reward.copy().dropna()  # Avoid overwriting original df\n",
    "    df_reward[\"last_action\"] = df_reward[\"last_action\"].astype(np.uint8)\n",
    "    mean_reward_per_action = df_reward[[\"last_action\", \"reward\"]].groupby(\"last_action\").mean()\n",
    "    sns.barplot(\n",
    "        x=mean_reward_per_action.index,\n",
    "        y=\"reward\",\n",
    "        data=mean_reward_per_action,\n",
    "        ax=ax,\n",
    "        order=ACTION_VALUE_MAPPING.values(),\n",
    "    )\n",
    "    ax.set_xticklabels(ACTION_VALUE_MAPPING.keys())\n",
    "    ax.set_xlabel(\"Action\")\n",
    "    ax.set_ylabel(\"Mean reward associated with the action\")\n",
    "    ax.set_title(f\"Mean reward per action\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.362645,
     "end_time": "2022-07-04T13:48:22.070462",
     "exception": false,
     "start_time": "2022-07-04T13:48:21.707817",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_mean_reward_per_action(df_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
