{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import is3_broker_rl\n",
    "from is3_broker_rl.api.dto import Action\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\"retina\")\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(is3_broker_rl.__file__).parent.parent / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Papermill parameter cell\n",
    "# Name of the directory to analyse. Should contain consumption_action.csv and consumption_reward.csv.\n",
    "ANALYSIS_DIR_NAME = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANALYSIS_DIR = DATA_DIR / ANALYSIS_DIR_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_action = pd.read_csv(ANALYSIS_DIR / \"consumption_action.csv\")\n",
    "df_reward = pd.read_csv(ANALYSIS_DIR / \"consumption_reward.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ACTION_VALUE_MAPPING = {a.name: a.value for a in Action}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_action_counts(df_action):\n",
    "    fig, ax = plt.subplots(figsize=(16, 9))\n",
    "    sns.countplot(x=\"action\", data=df_action, ax=ax, order=ACTION_VALUE_MAPPING.values())\n",
    "    ax.set_xticklabels(ACTION_VALUE_MAPPING.keys())\n",
    "    ax.set_xlabel(\"Action type\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.set_title(\"Action distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_action_counts(df_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_action_count_over_time(df_action):\n",
    "    fig, axs = plt.subplots(figsize=(21, 14), nrows=len(ACTION_VALUE_MAPPING))\n",
    "    action_value_counts = (\n",
    "        df_action[[\"gameId\", \"action\"]]\n",
    "        .groupby([\"gameId\", \"action\"], sort=False)\n",
    "        .size()\n",
    "        .unstack(fill_value=0)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    for i, action_value in enumerate(ACTION_VALUE_MAPPING.values()):\n",
    "        ax = axs.flat[i]\n",
    "        sns.lineplot(data=action_value_counts[action_value], ax=ax)\n",
    "        ax.set_title(f\"Number of action={list(ACTION_VALUE_MAPPING.keys())[action_value]} over time for each game\")\n",
    "        ax.set_xlabel(\"Game number\")\n",
    "        ax.set_ylabel(\"Action count\")\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_action_count_over_time(df_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_episode_reward(df_reward, df_action):\n",
    "    fig, ax = plt.subplots(figsize=(21, 11))\n",
    "    df_mean_episode_reward = df_reward.groupby(\"episode_id\", sort=False).mean().reset_index()\n",
    "    df_max_episode_reward = df_reward.groupby(\"episode_id\", sort=False).max().reset_index()\n",
    "    df_min_episode_reward = df_reward.groupby(\"episode_id\", sort=False).min().reset_index()\n",
    "    sns.lineplot(\n",
    "        x=df_mean_episode_reward.index, y=\"reward\", data=df_mean_episode_reward, ax=ax, label=\"Mean episode reward\"\n",
    "    )\n",
    "    sns.lineplot(\n",
    "        x=df_max_episode_reward.index, y=\"reward\", data=df_max_episode_reward, ax=ax, label=\"Max episode reward\"\n",
    "    )\n",
    "    sns.lineplot(\n",
    "        x=df_min_episode_reward.index, y=\"reward\", data=df_min_episode_reward, ax=ax, label=\"Min episode reward\"\n",
    "    )\n",
    "    df_episode_game_id = df_reward.groupby(\"episode_id\", sort=False)[\"gameId\"].first().reset_index()\n",
    "    ax.vlines(\n",
    "        df_episode_game_id[df_episode_game_id[\"gameId\"].shift() != df_episode_game_id[\"gameId\"]].index,\n",
    "        0,\n",
    "        1,\n",
    "        transform=ax.get_xaxis_transform(),\n",
    "        colors=\"r\",\n",
    "        alpha=0.3,\n",
    "        label=\"New game\",\n",
    "    )\n",
    "    ax.set_xlabel(\"Episode\")\n",
    "    ax.set_ylabel(\"Aggregated reward\")\n",
    "    ax.legend()\n",
    "    ax.set_title(f\"Episode reward (N_EPISODES: {df_reward['episode_id'].nunique()}, N_TIMESTEPS: {len(df_action)})\")\n",
    "    ax.margins(x=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_episode_reward(df_reward, df_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_episode_reward_reg(df_reward, df_action):\n",
    "    fig, ax = plt.subplots(figsize=(21, 11))\n",
    "    df_mean_episode_reward = df_reward.groupby(\"episode_id\", sort=False).mean().reset_index()\n",
    "    sns.regplot(\n",
    "        x=df_mean_episode_reward.index,\n",
    "        y=\"reward\",\n",
    "        data=df_mean_episode_reward,\n",
    "        scatter=True,\n",
    "        marker=\".\",\n",
    "        ax=ax,\n",
    "        label=\"Mean episode reward\",\n",
    "        line_kws={\"label\": \"OLS fit\"},\n",
    "    )\n",
    "    df_episode_game_id = df_reward.groupby(\"episode_id\", sort=False)[\"gameId\"].first().reset_index()\n",
    "    ax.vlines(\n",
    "        df_episode_game_id[df_episode_game_id[\"gameId\"].shift() != df_episode_game_id[\"gameId\"]].index,\n",
    "        0,\n",
    "        1,\n",
    "        transform=ax.get_xaxis_transform(),\n",
    "        colors=\"r\",\n",
    "        alpha=0.3,\n",
    "        label=\"New game\",\n",
    "    )\n",
    "    ax.set_xlabel(\"Episode\")\n",
    "    ax.set_ylabel(\"Aggregated reward\")\n",
    "    ax.legend()\n",
    "    ax.set_title(\n",
    "        f\"Mean episode reward (N_EPISODES: {df_reward['episode_id'].nunique()}, N_TIMESTEPS: {len(df_action)})\"\n",
    "    )\n",
    "    ax.margins(x=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_episode_reward_reg(df_reward, df_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.01032,
     "end_time": "2022-06-27T14:18:45.498030",
     "exception": false,
     "start_time": "2022-06-27T14:18:45.487710",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_mean_reward_per_action(df_reward, df_action):\n",
    "    fig, ax = plt.subplots(figsize=(21, 11))\n",
    "    df_reward = df_reward.copy().dropna()  # Avoid overwriting original df\n",
    "    df_reward[\"last_action\"] = df_reward[\"last_action\"].astype(np.uint8)\n",
    "    mean_reward_per_action = df_reward[[\"last_action\", \"reward\"]].groupby(\"last_action\").mean()\n",
    "    sns.barplot(\n",
    "        x=mean_reward_per_action.index,\n",
    "        y=\"reward\",\n",
    "        data=mean_reward_per_action,\n",
    "        ax=ax,\n",
    "        order=ACTION_VALUE_MAPPING.values(),\n",
    "    )\n",
    "    ax.set_xticklabels(ACTION_VALUE_MAPPING.keys())\n",
    "    ax.set_xlabel(\"Action\")\n",
    "    ax.set_ylabel(\"Mean reward associated with the action\")\n",
    "    actions_per_episode = df_action[\"episode_id\"].groupby(df_action[\"episode_id\"]).count().iloc[0]\n",
    "    rewards_per_episode = df_reward[\"episode_id\"].groupby(df_reward[\"episode_id\"]).count().iloc[0]\n",
    "    # One iteration is the number of timesteps where rewards are collected for the last predicted action\n",
    "    ax.set_title(\n",
    "        f\"Mean reward per action (Iteration duration: {rewards_per_episode / actions_per_episode:.0f} timeslots)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_reward_per_action(df_reward, df_action)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
